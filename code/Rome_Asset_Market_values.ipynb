{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "# from shapely.ops import unary_union\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "# from shapely.ops import nearest_points\n",
    "\n",
    "from tobler.area_weighted import area_interpolate\n",
    "# from tobler.dasymetric import masked_area_interpolate\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import contextily as cx\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterstats import zonal_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Volumes/Extreme SSD/MH_Suitability/dati/32633_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AOI\n",
    "AOI = gpd.read_file(\"AOI.gpkg\", ignore_fields=['location', 'id', 'objectid', 'cod_pro',\n",
    "                                               'cod_istat', 'pro_com', 'nome', 'shape_leng', 'shape_area'])\n",
    "\n",
    "# MUNICIPI\n",
    "mun = gpd.read_file(\"ASSETS/municipi_Roma_32633.gpkg\")\n",
    "\n",
    "# CENSUS\n",
    "census = gpd.read_file(\"ASSETS/sez_censuarie_2011_Roma_32633.gpkg\",\n",
    "                       ignore_fields=['pro_com', 'cod_stagno','cod_fiume', \n",
    "                                      'cod_lago', 'cod_laguna', 'cod_val_p', 'cod_zona_c',\n",
    "                                      'cod_is_amm', 'cod_is_lac', 'cod_is_mar', 'cod_area_s', 'cod_mont_d',\n",
    "                                      'loc2011', 'cod_loc', 'tipo_loc', 'com_asc', 'cod_asc', 'ace',\n",
    "                                      'shape_leng'\n",
    "                                      ]\n",
    "                       )\n",
    "\n",
    "# OMI\n",
    "omi = gpd.read_file(\"ASSETS/OMI_Zone_Valori_32633.gpkg\",\n",
    "                    ignore_fields=['LINKZONA', 'CODCOM', 'ZONE_Comune_descrizione',\n",
    "                           'ZONE_Zona_Descr', 'ZONE_Zona', 'ZONE_LinkZona', 'ZONE_Stato_prev', 'ZONE_Microzona',\n",
    "                           'VAL_Zona', 'VAL_Fascia', 'VAL_Stato_prev', 'VAL_Sup_NL_compr', \n",
    "                           'VAL_Loc_min', 'VAL_Loc_max', 'VAL_Sup_NL_loc'\n",
    "                           ]\n",
    "                    )\n",
    "\n",
    "# BUILDINGS\n",
    "BUILD = gpd.read_file(\"ASSETS/dbsn_edifici_AOI_32633.gpkg\",\n",
    "                      ignore_fields=['edifc_sot', 'classid', 'edifc_nome', 'edifc_stat', \n",
    "                                     'edifc_at', 'scril', 'meta_ist', 'edifc_mon', \n",
    "                                     'shape_Length', 'shape_Area']\n",
    "                      ).set_index('OBJECTID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Reading input data\n",
    "\n",
    "\n",
    "#%% OVERLAY with AOI\n",
    "mun_aoi = gpd.clip(mun, AOI)\n",
    "census_aoi = gpd.clip(census, AOI)\n",
    "omi_aoi = gpd.clip(omi, AOI)\n",
    "\n",
    "# delete original gdf\n",
    "del mun, census, omi\n",
    "\n",
    "#%% FUNCTIONS\n",
    "\n",
    "# Merge categories of \"edifc_uso\"\n",
    "def merge_category(cat):\n",
    "    macro_cats = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '95', '93']\n",
    "    for macro in macro_cats:\n",
    "        if cat.startswith(macro):\n",
    "            return macro\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def fill_missing_values(gdf, col, k=3):\n",
    "    # creiamo una copia del geodataframe per evitare di modificare l'originale\n",
    "    filled_gdf = gdf.copy()\n",
    "    \n",
    "    # selezioniamo i record con valore nullo nella colonna \"VAL_Compr_min\"\n",
    "    null_rows = filled_gdf[filled_gdf[col].isnull()]\n",
    "        \n",
    "    # iteriamo sui record con valore nullo\n",
    "    for idx, row in null_rows.iterrows():\n",
    "        # selezioniamo i tre poligoni più vicini al punto di interesse\n",
    "        point = Point(row[\"geometry\"].centroid.x, row[\"geometry\"].centroid.y)\n",
    "        distances = filled_gdf.distance(point)\n",
    "        nearest_poly_indices = distances.sort_values().index[:k]\n",
    "        \n",
    "        # calcoliamo la media dei valori \"VAL_Compr_min\" dei tre poligoni vicini\n",
    "        nearest_vals = filled_gdf[~filled_gdf.index.isin([idx]) & filled_gdf.index.isin(nearest_poly_indices)][col]\n",
    "        mean_val = nearest_vals.mean()\n",
    "        \n",
    "        # sostituiamo il valore nullo con la media dei valori dei poligoni vicini\n",
    "        filled_gdf.loc[idx, col] = mean_val\n",
    "        # check remaining NANs and fill them with mean value of the series.\n",
    "        # filled_gdf.fillna()\n",
    "    return filled_gdf\n",
    "\n",
    "def fill_missing_values_by_type(gdf, col, col_type='VAL_Descr_Tipologia', k=3):\n",
    "    # creo empty geodataframe\n",
    "    result_gdf = gpd.GeoDataFrame(crs='EPSG:32633')\n",
    "    # iterate on types\n",
    "    types = gdf[col_type].unique()\n",
    "    for t in types:\n",
    "        filled_gdf_type = gdf.loc[gdf[col_type] == t]\n",
    "        # selezioniamo i record con valore nullo nella colonna \"VAL_Compr_min\"\n",
    "        null_rows = filled_gdf_type.loc[filled_gdf_type[col].isnull()]\n",
    "        # iteriamo sui record con valore nullo\n",
    "        for idx, row in null_rows.iterrows():\n",
    "            # selezioniamo i tre poligoni più vicini al punto di interesse\n",
    "            point = Point(row[\"geometry\"].centroid.x, row[\"geometry\"].centroid.y)\n",
    "            distances = filled_gdf_type.distance(point)\n",
    "            nearest_poly_indices = distances.sort_values().index[:k]\n",
    "            \n",
    "            # calcoliamo la media dei valori \"VAL_Compr_min\" dei tre poligoni vicini\n",
    "            nearest_vals = filled_gdf_type[~filled_gdf_type.index.isin([idx]) & filled_gdf_type.index.isin(nearest_poly_indices)][col]\n",
    "            mean_val = nearest_vals.mean()\n",
    "            \n",
    "            # sostituiamo il valore nullo con la media dei valori dei poligoni vicini\n",
    "            filled_gdf_type.loc[idx, col] = mean_val\n",
    "            # check remaining NANs and fill them with mean value of the series.\n",
    "        mean_by_col_type = filled_gdf_type[col].mean()\n",
    "        filled_gdf_type[col].fillna(mean_by_col_type, inplace=True)\n",
    "    \n",
    "        # append to results\n",
    "        result_gdf = result_gdf.append(filled_gdf_type)\n",
    "    return result_gdf\n",
    "\n",
    "# Spatial joint between polygon with the largest area of intersection\n",
    "def largest_intersection(gdf_left, gdf_right, mode):\n",
    "    \"\"\"\n",
    "    Take two geodataframes, do a spatial join, and return the polygon \n",
    "    with the largest area of intersection\n",
    "    \"\"\"\n",
    "    out_gdf = gpd.sjoin(gdf_left, gdf_right, how = \"left\", predicate = mode).dropna()\n",
    "    out_gdf['intersection'] = [a.intersection(gdf_right[gdf_right.index == b].geometry.values[0]).area for a, b in zip(out_gdf.geometry.values, out_gdf.index_right)]\n",
    "    out_gdf['index'] = out_gdf.index\n",
    "    out_gdf = out_gdf.sort_values(by='intersection')\n",
    "    out_gdf = out_gdf.drop_duplicates(subset = 'index', keep='last')\n",
    "    out_gdf = out_gdf.sort_values(by='index')\n",
    "    out_gdf = out_gdf.drop(columns=['index_right', 'intersection', 'index'])\n",
    "    \n",
    "    return out_gdf\n",
    "\n",
    "\n",
    "def open_raster(raster_file_path):\n",
    "    with rasterio.open(raster_file_path) as src:\n",
    "        #get transform\n",
    "        transform = src.meta['transform']\n",
    "        #create 2darray from band 1\n",
    "        array = src.read(1)\n",
    "        print(\"Array shape: \", array.shape)\n",
    "        \n",
    "        print('src type: ', type(src))\n",
    "        # get raster profile\n",
    "        print('no data value: ', src.nodata)\n",
    "        kwds = src.profile\n",
    "\n",
    "        return array, kwds, transform\n",
    "\n",
    "def save_raster(raster_array, name, kwds):\n",
    "    with rasterio.open(os.path.join(name+\".tif\"), 'w', **kwds) as dst:\n",
    "        dst.write(raster_array, indexes=1)\n",
    "\n",
    "#%% Pre-processing\n",
    "\n",
    "## SPATIAL FILL NAN --> Func fill_missing_values\n",
    "most_fr = omi_aoi['VAL_Descr_Tipologia'].mode().iloc[0]\n",
    "omi_aoi['VAL_Descr_Tipologia'].fillna(most_fr, inplace=True)\n",
    "omi_20 = omi_aoi[omi_aoi['VAL_Descr_Tipologia'].isin(['Abitazioni civili', 'Ville e Villini'])]\n",
    "omi_20_fill = fill_missing_values(omi_20, \"VAL_Compr_min\", k=3)\n",
    "omi_20_fill_ok = fill_missing_values(omi_20_fill, \"VAL_Compr_max\", k=3)\n",
    "omi_20_nan = omi_20_fill_ok[omi_20_fill_ok['VAL_Cod_Tip'].isna()]\n",
    "# assign filled values to original omi_aoi\n",
    "omi_aoi['VAL_Compr_min'].fillna(omi_20_nan['VAL_Compr_min'], inplace=True)\n",
    "omi_aoi['VAL_Compr_max'].fillna(omi_20_nan['VAL_Compr_max'], inplace=True)\n",
    "del most_fr, omi_20, omi_20_fill, omi_20_fill_ok, omi_20_nan\n",
    "# save omi_aoi\n",
    "omi_aoi.to_file(\"ASSETS/pre-processed/OMI_AOI.gpkg\", driver='GPKG')\n",
    "\n",
    "## Spatial Join BUILD-OMI \n",
    "# select unique omi polygons with codzona attribute\n",
    "omi_codzona = omi_aoi[['CODZONA', 'geometry']].sort_index().drop_duplicates(subset=['CODZONA', 'geometry'])\n",
    "# spatial join one-to-one BUILD with omi_codzona\n",
    "builds_codzona = largest_intersection(BUILD, omi_codzona, 'intersects')\n",
    "## Buildings Macro Categories\n",
    "builds_codzona['edifc_uso_macro'] = builds_codzona['edifc_uso'].apply(merge_category)\n",
    "builds_codzona = builds_codzona.reset_index()\n",
    "del BUILD\n",
    "# save builds_codzona\n",
    "builds_codzona.to_file(\"ASSETS/pre-processed/builds_w_codzona.gpkg\", driver='GPKG')\n",
    "\n",
    "#%% READ builds_w_codzona and OMI_AOI\n",
    "builds_codzona = gpd.read_file(\"ASSETS/pre-processed/builds_w_codzona.gpkg\")\n",
    "omi_aoi = gpd.read_file(\"ASSETS/pre-processed/OMI_AOI.gpkg\")\n",
    "# MAP Cod_Tip and Edific_Uso\n",
    "# corrispondenze valori edifc_uso, VAL_Cod_Tip\n",
    "edifc_uso_map = {'01':'Abitazioni civili',\n",
    "                 '02':'Uffici',\n",
    "                 # '03': 'Abitazioni di tipo economico',\n",
    "                 '03': 'Uffici',\n",
    "                 '04': 'Uffici',\n",
    "                 '05': '-',\n",
    "                 '06': 'Abitazioni di tipo economico',\n",
    "                 '07': 'Negozi',\n",
    "                 '08': 'Capannoni industriali',\n",
    "                 '09': 'Capannoni tipici',\n",
    "                 '10': 'Abitazioni di tipo economico', # o abitazioni civili\n",
    "                 '11': 'Abitazioni di tipo economico',\n",
    "                 '12': 'Abitazioni di tipo economico', # o abitazioni civili\n",
    "                 '95':'-',\n",
    "                 '93':'-'}\n",
    "# vista la problematica sul valore economico beni culturali (05), li rimuovo dalle analisi (luoghi di culto)\n",
    "# insieme anche a militare (04), carcere (11), altro (95), e non definito (93)\n",
    "\n",
    "# map\n",
    "builds_codzona['VAL_Descr_Tipologia'] = builds_codzona['edifc_uso_macro'].map(edifc_uso_map)\n",
    "# drop '-'\n",
    "builds_codzona = builds_codzona.drop(builds_codzona[builds_codzona['VAL_Descr_Tipologia'] == '-'].index)\n",
    "\n",
    "# MERGE [VAL_Compr_min, VAL_Compr_max] on [CODZONA, VAL_Cod_Tip]\n",
    "builds_w_val = builds_codzona.merge(omi_aoi, on=['CODZONA','VAL_Descr_Tipologia'], how='left',\n",
    "                                    ).drop(columns=['geometry_y']\n",
    "                                           # ).set_index('OBJECTID'\n",
    "                                           ).rename(columns={'geometry_x': 'geometry'}\n",
    "                                                    ).set_geometry('geometry')\n",
    "                                                    # droppa colonne inutili\n",
    "# sort values and drop_duplicates keeping last\n",
    "builds_w_val = builds_w_val.sort_values(by=['OBJECTID', 'VAL_Compr_min']\n",
    "                                        ).drop_duplicates(subset=['OBJECTID'], keep='last')\n",
    "# Fill NAN with knn\n",
    "#check NAN\n",
    "print(builds_w_val.isna().sum())\n",
    "\n",
    "builds_w_val_filled = fill_missing_values_by_type(builds_w_val, 'VAL_Compr_min', col_type='VAL_Descr_Tipologia', k=10)\n",
    "builds_w_val_filled2 = fill_missing_values_by_type(builds_w_val_filled, 'VAL_Compr_max', col_type='VAL_Descr_Tipologia', k=10)\n",
    "del builds_w_val_filled\n",
    "\n",
    "#drop useless cols\n",
    "cols_to_drop = ['Name', 'ZONE_Fascia', 'ZONE_Cod_tip_prev', 'ZONE_Descr_tip_prev', 'VAL_Cod_Tip', 'VAL_Stato']\n",
    "builds_w_val_filled_ok = builds_w_val_filled2.drop(cols_to_drop, axis=1)\n",
    "# drop nan\n",
    "builds_w_val_filled_ok.dropna(inplace=True)\n",
    "\n",
    "# save builds_w_val\n",
    "builds_w_val_filled_ok.to_file(\"ASSETS/pre-processed/builds_w_val_filled_by_type_new.gpkg\", driver='GPKG')\n",
    "#-------------------------------------------------------------------------\n",
    "# Filter on condition\n",
    "# builds_w_val_filled_ok = gpd.read_file(\"ASSETS/pre-processed/builds_w_val_filled_by_type_new.gpkg\")\n",
    "condition = ((builds_w_val_filled_ok['edifc_uso_macro'] == '10') & builds_w_val_filled_ok['edifc_ty'].isin(['11', '12', '15', '16', '95']))\n",
    "builds_w_omi = builds_w_val_filled_ok.drop(builds_w_val_filled_ok[condition].index)\n",
    "#save gdf\n",
    "builds_w_omi.to_file(\"ASSETS/pre-processed/builds_w_omi_all.gpkg\", driver='GPKG')\n",
    "\n",
    "#%% SJOIN BUILDS w CENSUS\n",
    "# spatial join one-to-one between buildings and census.\n",
    "cols_of_interest = ['id', 'geometry']\n",
    "cens_id = census_aoi[cols_of_interest].rename(columns={'id':'c_parcel_id'})\n",
    "builds_w_all = largest_intersection(builds_w_omi, cens_id, 'intersects')\n",
    "# drop rows with VAL_Descr_Tipologia == '-'.\n",
    "builds_w_all = builds_w_all.drop(builds_w_all[builds_w_all['VAL_Descr_Tipologia'] == '-'].index)\n",
    "\n",
    "\n",
    "\n",
    "builds_w_all.to_file(\"ASSETS/pre-processed/builds_w_all.gpkg\", driver='GPKG')\n",
    "\n",
    "\n",
    "#%% SPATIAL INTERPOLATION WITH TOBLER\n",
    "# interpolation = area_interpolate(source_df=omi_aoi, target_df=census_aoi, intensive_variables=['VAL_Compr_min_fill'])\n",
    "# interpolation.to_file(\"tests/census_w_omi_spatial_interpolation.gpkg\", driver='GPKG', layer='name')\n",
    "\n",
    "# buildings\n",
    "# interp_build = area_interpolate(omi_aoi, BUILD, intensive_variables=['VAL_Compr_min_fill', 'VAL_Compr_max_fill'])\n",
    "# interp_build.to_file(\"tests/builds_w_omi_spatial_interpolation.gpkg\", driver='GPKG', layer='name')\n",
    "\n",
    "#%% PLOT VECTORS\n",
    "\n",
    "# font = {'family' : 'Sans Serif',\n",
    "#         'size'   : 18}\n",
    "# plt.rc('font', **font)\n",
    "plt.rc('font', size=20)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=16)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=16)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=20)    # legend fontsize\n",
    "plt.rc('figure', titlesize=22)  # fontsize of the figure title\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16), dpi=300, facecolor='w', edgecolor='k')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "cx_crs = 'EPSG:3857'\n",
    "AOI.to_crs(cx_crs).boundary.plot(ax=ax, color='k')\n",
    "omi_codzona.to_crs(cx_crs).boundary.plot(ax=ax, color='k', lw=0.5, zorder=1)\n",
    "\n",
    "builds_w_val_filled2.to_crs(cx_crs).plot(ax=ax, column='VAL_Compr_max', cmap='rainbow', zorder=2,\n",
    "                          legend=True, cax=cax, legend_kwds={'label':'Euro/mq',\n",
    "                                                    'orientation':'vertical'})\n",
    "\n",
    "\n",
    "# interp_build.plot(ax=ax, column='VAL_Compr_max_fill', linewidth=0.1)\n",
    "\n",
    "# add basemap\n",
    "# cx.add_basemap(ax=ax, source=cx.providers.Stamen.TonerLite)\n",
    "# cx.add_basemap(ax, source=cx.providers.Esri.WorldTerrain) #WorldTerrain, WorldShadedRelief\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "# set labels, title and legend\n",
    "# plt.title('Building Value', fontsize=32)\n",
    "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "# add scalebar\n",
    "ax.add_artist(ScaleBar(2, location='lower right', box_color='w',\n",
    "                       font_properties={'size':'large'}))\n",
    "\n",
    "# SAVE\n",
    "PLOT_NAME= 'Building Value by location and type'\n",
    "path= \"C:/Users/giand/Documents/PhD_Scienze_della_Terra/Database_Hazard/Roma/MH_Suitability/figures\"\n",
    "plt.savefig(os.path.join(path, '{}.tiff').format(PLOT_NAME), format='tiff', bbox_inches='tight', pad_inches=0.2)\n",
    "\n",
    "plt.show()\n",
    "#%% ZONAL STATISTICS\n",
    "stats = ['count', 'mean', 'median', 'std', 'percentile_05', 'percentile_95', 'max']\n",
    "# Buildings\n",
    "builds = gpd.read_file(\"ASSETS/pre-processed/builds_w_val_filled_by_type.gpkg\",\n",
    "                       ignore_fields=['edifc_uso', 'edifc_ty', 'CODZONA',\n",
    "                                      'edifc_uso_macro', 'VAL_Descr_Tipologia',\n",
    "                                      'Name', 'ZONE_Fascia', 'ZONE_Cod_tip_prev',\n",
    "                                      'ZONE_Descr_tip_prev', 'VAL_Cod_Tip', 'VAL_Stato',\n",
    "                                      'VAL_Compr_min', 'VAL_Compr_max'])\n",
    "# Buffering\n",
    "builds_buffer20 = builds.buffer(20, cap_style=3, join_style=2)\n",
    "\n",
    "#####  LANDSLIDE  #####\n",
    "filepath= \"SUSCEPTIBILITIES/landslide_pre2014_32633.tif\"\n",
    "# As NUMPY ARRAY\n",
    "LS_array, kwds_LS, transform_ls = open_raster(filepath)\n",
    "# replace nodata (-9999) with 0\n",
    "LS_array[LS_array == -9999] = 0\n",
    "# AS RASTERIO DATASET\n",
    "LS_rio = rasterio.open(filepath)\n",
    "affine_ls = LS_rio.transform\n",
    "# Zonal stats on buildings: count-mean-median-st.dev-variance.\n",
    "zs_ls = zonal_stats(builds_buffer20, LS_array, affine=transform_ls, stats=stats, prefix='ls_', categorical=False, category_map=None)\n",
    "zs_ls_df = pd.DataFrame(zs_ls); del zs_ls\n",
    "builds_ls = builds.merge(zs_ls_df, left_index=True, right_index=True)\n",
    "# save file\n",
    "# builds_ls.to_file(\"SUSCEPTIBILITIES/ZONAL_STATS/builds_ls.gpkg\", driver='GPKG')\n",
    "\n",
    "##### SUBSIDENCE  #######\n",
    "filepath= \"SUSCEPTIBILITIES\\susc_subdidenza_32633_esteso_rescaled.tif\"\n",
    "# As NUMPY ARRAY\n",
    "SUBS_array, kwds_SUBS, transform_subs = open_raster(filepath)\n",
    "# replace nodata (255) with NAN\n",
    "# SUBS_array[SUBS_array == 255] = 0\n",
    "# AS RASTERIO DATASET\n",
    "SUBS_rio = rasterio.open(filepath)\n",
    "affine_subs = SUBS_rio.transform\n",
    "# Zonal stats on buildings: count-mean-median-st.dev-variance.\n",
    "zs_subs = zonal_stats(builds, SUBS_array, affine=transform_subs, stats=stats, prefix='subs_', categorical=False, category_map=None)\n",
    "zs_subs_df = pd.DataFrame(zs_subs); #del zs_subs\n",
    "builds_subs = builds.merge(zs_subs_df, left_index=True, right_index=True)\n",
    "#save file\n",
    "builds_subs.to_file(\"SUSCEPTIBILITIES/ZONAL_STATS/builds_subs_rescaled.gpkg\", driver='GPKG')\n",
    "\n",
    "\n",
    "#####  SINKHOLE  #####\n",
    "filepath= \"SUSCEPTIBILITIES/SHSI_32633.tif\"\n",
    "# As NUMPY ARRAY\n",
    "SHSI_array, kwds_SHSI, transform_SHSI = open_raster(filepath)\n",
    "# replace nodata (255) with NAN\n",
    "# SHSI_array[SHSI_array == -9999] = 0\n",
    "# AS RASTERIO DATASET\n",
    "SHSI_rio = rasterio.open(filepath)\n",
    "affine_SHSI = SHSI_rio.transform\n",
    "# Zonal stats on buildings: count-mean-median-st.dev-variance.\n",
    "zs_SHSI = zonal_stats(builds, SHSI_array, affine=transform_SHSI, stats=stats, prefix='shsi_', categorical=False, category_map=None)\n",
    "zs_shsi_df = pd.DataFrame(zs_SHSI)\n",
    "builds_shsi = builds.merge(zs_shsi_df, left_index=True, right_index=True)\n",
    "#save file\n",
    "builds_shsi.to_file(\"SUSCEPTIBILITIES/ZONAL_STATS/builds_shsi.gpkg\", driver='GPKG')\n",
    "#%% PLOT RASTERS and VECTORS\n",
    "RASTER_ARRAY = SUBS_array\n",
    "RASTER_RIO = SUBS_rio\n",
    "AFFINE = affine_subs\n",
    "LAYER = 'Subsidence Susceptibility'\n",
    "#----------------\n",
    "fig, ax = plt.subplots(figsize=(16, 16), dpi=100, facecolor='w', edgecolor='k')\n",
    "# raster\n",
    "image_hidden = ax.imshow(RASTER_ARRAY, cmap='RdYlGn_r')\n",
    "# plot on the same axis with rio.plot.show\n",
    "image = show(RASTER_RIO, transform=AFFINE, ax=ax, cmap='RdYlGn_r')\n",
    "# add colorbar using the now hidden image\n",
    "fig.colorbar(image_hidden, ax=ax)\n",
    "# show(SUBS_rio, ax=ax, cmap='plasma')\n",
    "\n",
    "# vectors\n",
    "# AOI.boundary.plot(ax=ax)\n",
    "# builds.plot(ax=ax, color=\"k\", lw=0.4)\n",
    "\n",
    "\n",
    "# add basemap\n",
    "# cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "# set labels, title and legend\n",
    "plt.title(LAYER, fontsize=32)\n",
    "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "# add scalebar\n",
    "ax.add_artist(ScaleBar(2, location='lower right', box_color='w',\n",
    "                       font_properties={'size':'large'}))\n",
    "# SAVE\n",
    "PLOT_NAME= LAYER\n",
    "path= \"C:/Users/giand/Documents/PhD_Scienze_della_Terra/Database_Hazard/Roma/MH_Suitability/figures\"\n",
    "# plt.savefig(os.path.join(path, '{}.tiff').format(PLOT_NAME), format='tiff', bbox_inches='tight', pad_inches=0.2)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
