{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "# from shapely.ops import unary_union\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "# from shapely.ops import nearest_points\n",
    "\n",
    "from tobler.area_weighted import area_interpolate\n",
    "# from tobler.dasymetric import masked_area_interpolate\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import contextily as cx\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterstats import zonal_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Volumes/Extreme SSD/MH_Suitability/dati/32633_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AOI\n",
    "AOI = gpd.read_file(\"AOI.gpkg\", ignore_fields=['location', 'id', 'objectid', 'cod_pro',\n",
    "                                               'cod_istat', 'pro_com', 'nome', 'shape_leng', 'shape_area'])\n",
    "\n",
    "# MUNICIPI\n",
    "mun = gpd.read_file(\"ASSETS/municipi_Roma_32633.gpkg\")\n",
    "\n",
    "# CENSUS\n",
    "census = gpd.read_file(\"ASSETS/sez_censuarie_2011_Roma_32633.gpkg\",\n",
    "                       ignore_fields=['pro_com', 'cod_stagno','cod_fiume', \n",
    "                                      'cod_lago', 'cod_laguna', 'cod_val_p', 'cod_zona_c',\n",
    "                                      'cod_is_amm', 'cod_is_lac', 'cod_is_mar', 'cod_area_s', 'cod_mont_d',\n",
    "                                      'loc2011', 'cod_loc', 'tipo_loc', 'com_asc', 'cod_asc', 'ace',\n",
    "                                      'shape_leng'\n",
    "                                      ]\n",
    "                       )\n",
    "\n",
    "# OMI\n",
    "omi = gpd.read_file(\"ASSETS/OMI_Zone_Valori_32633.gpkg\",\n",
    "                    ignore_fields=['LINKZONA', 'CODCOM', 'ZONE_Comune_descrizione',\n",
    "                           'ZONE_Zona_Descr', 'ZONE_Zona', 'ZONE_LinkZona', 'ZONE_Stato_prev', 'ZONE_Microzona',\n",
    "                           'VAL_Zona', 'VAL_Fascia', 'VAL_Stato_prev', 'VAL_Sup_NL_compr', \n",
    "                           'VAL_Loc_min', 'VAL_Loc_max', 'VAL_Sup_NL_loc'\n",
    "                           ]\n",
    "                    )\n",
    "\n",
    "# BUILDINGS\n",
    "BUILD = gpd.read_file(\"ASSETS/dbsn_edifici_AOI_32633.gpkg\",\n",
    "                      ignore_fields=['edifc_sot', 'classid', 'edifc_nome', 'edifc_stat', \n",
    "                                     'edifc_at', 'scril', 'meta_ist', 'edifc_mon', \n",
    "                                     'shape_Length', 'shape_Area']\n",
    "                      ).set_index('OBJECTID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Clip based on AOI\n",
    "mun_aoi = gpd.clip(mun, AOI)\n",
    "census_aoi = gpd.clip(census, AOI)\n",
    "omi_aoi = gpd.clip(omi, AOI)\n",
    "\n",
    "# delete original gdf\n",
    "del mun, census, omi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "# Merge categories of \"edifc_uso\"\n",
    "def merge_category(cat):\n",
    "    macro_cats = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '95', '93']\n",
    "    for macro in macro_cats:\n",
    "        if cat.startswith(macro):\n",
    "            return macro\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def fill_missing_values(gdf, col, k=3):\n",
    "    # creiamo una copia del geodataframe per evitare di modificare l'originale\n",
    "    filled_gdf = gdf.copy()\n",
    "    \n",
    "    # selezioniamo i record con valore nullo nella colonna \"VAL_Compr_min\"\n",
    "    null_rows = filled_gdf[filled_gdf[col].isnull()]\n",
    "        \n",
    "    # iteriamo sui record con valore nullo\n",
    "    for idx, row in null_rows.iterrows():\n",
    "        # selezioniamo i tre poligoni più vicini al punto di interesse\n",
    "        point = Point(row[\"geometry\"].centroid.x, row[\"geometry\"].centroid.y)\n",
    "        distances = filled_gdf.distance(point)\n",
    "        nearest_poly_indices = distances.sort_values().index[:k]\n",
    "        \n",
    "        # calcoliamo la media dei valori \"VAL_Compr_min\" dei tre poligoni vicini\n",
    "        nearest_vals = filled_gdf[~filled_gdf.index.isin([idx]) & filled_gdf.index.isin(nearest_poly_indices)][col]\n",
    "        mean_val = nearest_vals.mean()\n",
    "        \n",
    "        # sostituiamo il valore nullo con la media dei valori dei poligoni vicini\n",
    "        filled_gdf.loc[idx, col] = mean_val\n",
    "        # check remaining NANs and fill them with mean value of the series.\n",
    "        # filled_gdf.fillna()\n",
    "    return filled_gdf\n",
    "\n",
    "def fill_missing_values_by_type(gdf, col, col_type='VAL_Descr_Tipologia', k=3):\n",
    "    # creo empty geodataframe\n",
    "    result_gdf = gpd.GeoDataFrame(columns=['geometry'], geometry='geometry', crs='EPSG:32633')\n",
    "    # iterate on types\n",
    "    types = gdf[col_type].unique()\n",
    "    for t in types:\n",
    "        filled_gdf_type = gdf.loc[gdf[col_type] == t]\n",
    "        # selezioniamo i record con valore nullo nella colonna \"VAL_Compr_min\"\n",
    "        null_rows = filled_gdf_type.loc[filled_gdf_type[col].isnull()]\n",
    "        # iteriamo sui record con valore nullo\n",
    "        for idx, row in null_rows.iterrows():\n",
    "            # selezioniamo i tre poligoni più vicini al punto di interesse\n",
    "            point = Point(row[\"geometry\"].centroid.x, row[\"geometry\"].centroid.y)\n",
    "            distances = filled_gdf_type.distance(point)\n",
    "            nearest_poly_indices = distances.sort_values().index[:k]\n",
    "            \n",
    "            # calcoliamo la media dei valori \"VAL_Compr_min\" dei tre poligoni vicini\n",
    "            nearest_vals = filled_gdf_type[~filled_gdf_type.index.isin([idx]) & filled_gdf_type.index.isin(nearest_poly_indices)][col]\n",
    "            mean_val = nearest_vals.mean()\n",
    "            \n",
    "            # sostituiamo il valore nullo con la media dei valori dei poligoni vicini\n",
    "            filled_gdf_type.loc[idx, col] = mean_val\n",
    "            # check remaining NANs and fill them with mean value of the series.\n",
    "        mean_by_col_type = filled_gdf_type[col].mean()\n",
    "        filled_gdf_type[col].fillna(mean_by_col_type, inplace=True)\n",
    "    \n",
    "        # append to results\n",
    "        result_gdf = result_gdf.append(filled_gdf_type)\n",
    "    return result_gdf\n",
    "\n",
    "# Spatial joint between polygon with the largest area of intersection\n",
    "def largest_intersection(gdf_left, gdf_right, mode):\n",
    "    \"\"\"\n",
    "    Take two geodataframes, do a spatial join, and return the polygon \n",
    "    with the largest area of intersection\n",
    "    \"\"\"\n",
    "    out_gdf = gpd.sjoin(gdf_left, gdf_right, how = \"left\", predicate = mode).dropna()\n",
    "    out_gdf['intersection'] = [a.intersection(gdf_right[gdf_right.index == b].geometry.values[0]).area for a, b in zip(out_gdf.geometry.values, out_gdf.index_right)]\n",
    "    out_gdf['index'] = out_gdf.index\n",
    "    out_gdf = out_gdf.sort_values(by='intersection')\n",
    "    out_gdf = out_gdf.drop_duplicates(subset = 'index', keep='last')\n",
    "    out_gdf = out_gdf.sort_values(by='index')\n",
    "    out_gdf = out_gdf.drop(columns=['index_right', 'intersection', 'index'])\n",
    "    \n",
    "    return out_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPATIAL FILL NAN --> Func fill_missing_values\n",
    "most_fr = omi_aoi['VAL_Descr_Tipologia'].mode().iloc[0]\n",
    "omi_aoi['VAL_Descr_Tipologia'].fillna(most_fr, inplace=True)\n",
    "omi_20 = omi_aoi[omi_aoi['VAL_Descr_Tipologia'].isin(['Abitazioni civili', 'Ville e Villini'])]\n",
    "omi_20_fill = fill_missing_values(omi_20, \"VAL_Compr_min\", k=3)\n",
    "omi_20_fill_ok = fill_missing_values(omi_20_fill, \"VAL_Compr_max\", k=3)\n",
    "omi_20_nan = omi_20_fill_ok[omi_20_fill_ok['VAL_Cod_Tip'].isna()]\n",
    "# assign filled values to original omi_aoi\n",
    "omi_aoi['VAL_Compr_min'].fillna(omi_20_nan['VAL_Compr_min'], inplace=True)\n",
    "omi_aoi['VAL_Compr_max'].fillna(omi_20_nan['VAL_Compr_max'], inplace=True)\n",
    "del most_fr, omi_20, omi_20_fill, omi_20_fill_ok, omi_20_nan\n",
    "# save omi_aoi\n",
    "# omi_aoi.to_file(\"ASSETS/pre-processed/OMI_AOI.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spatial Join BUILD-OMI \n",
    "# select unique omi polygons with codzona attribute\n",
    "omi_codzona = omi_aoi[['CODZONA', 'geometry']].sort_index().drop_duplicates(subset=['CODZONA', 'geometry'])\n",
    "# spatial join one-to-one BUILD with omi_codzona\n",
    "builds_codzona = largest_intersection(BUILD, omi_codzona, 'intersects')\n",
    "## Buildings Macro Categories\n",
    "builds_codzona['edifc_uso_macro'] = builds_codzona['edifc_uso'].apply(merge_category)\n",
    "builds_codzona = builds_codzona.reset_index()\n",
    "del BUILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP Cod_Tip and Edific_Uso\n",
    "# corrispondenze valori edifc_uso, VAL_Cod_Tip\n",
    "edifc_uso_map = {'01':'Abitazioni civili',\n",
    "                 '02':'Uffici',\n",
    "                 # '03': 'Abitazioni di tipo economico',\n",
    "                 '03': 'Uffici',\n",
    "                 '04': 'Uffici',\n",
    "                 '05': '-',\n",
    "                 '06': 'Abitazioni di tipo economico',\n",
    "                 '07': 'Negozi',\n",
    "                 '08': 'Capannoni industriali',\n",
    "                 '09': 'Capannoni tipici',\n",
    "                 '10': 'Abitazioni di tipo economico', # o abitazioni civili\n",
    "                 '11': 'Abitazioni di tipo economico',\n",
    "                 '12': 'Abitazioni di tipo economico', # o abitazioni civili\n",
    "                 '95':'-',\n",
    "                 '93':'-'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map\n",
    "builds_codzona['VAL_Descr_Tipologia'] = builds_codzona['edifc_uso_macro'].map(edifc_uso_map)\n",
    "# drop '-'\n",
    "builds_codzona = builds_codzona.drop(builds_codzona[builds_codzona['VAL_Descr_Tipologia'] == '-'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE [VAL_Compr_min, VAL_Compr_max] on [CODZONA, VAL_Cod_Tip]\n",
    "builds_w_val = builds_codzona.merge(omi_aoi, on=['CODZONA','VAL_Descr_Tipologia'], how='left',\n",
    "                                    ).drop(columns=['geometry_y']\n",
    "                                           # ).set_index('OBJECTID'\n",
    "                                           ).rename(columns={'geometry_x': 'geometry'}\n",
    "                                                    ).set_geometry('geometry')\n",
    "                                                    # drop useless columns\n",
    "# sort values and drop_duplicates keeping last\n",
    "builds_w_val = builds_w_val.sort_values(by=['OBJECTID', 'VAL_Compr_min']\n",
    "                                        ).drop_duplicates(subset=['OBJECTID'], keep='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID                  0\n",
      "edifc_uso                 0\n",
      "edifc_ty                  0\n",
      "geometry                  0\n",
      "CODZONA                   0\n",
      "edifc_uso_macro           0\n",
      "VAL_Descr_Tipologia       0\n",
      "Name                   4074\n",
      "ZONE_Fascia            4074\n",
      "ZONE_Cod_tip_prev      4074\n",
      "ZONE_Descr_tip_prev    4074\n",
      "VAL_Cod_Tip            4456\n",
      "VAL_Stato              4456\n",
      "VAL_Compr_min          4074\n",
      "VAL_Compr_max          4074\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for NaNs\n",
    "print(builds_w_val.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n",
      "/var/folders/j3/ht1nhdx57gz8mgg616ylchmm0000gn/T/ipykernel_92378/835085651.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_gdf = result_gdf.append(filled_gdf_type)\n"
     ]
    }
   ],
   "source": [
    "# Fill NaNs with knn\n",
    "builds_w_val_filled = fill_missing_values_by_type(builds_w_val, 'VAL_Compr_min', col_type='VAL_Descr_Tipologia', k=10)\n",
    "builds_w_val_filled2 = fill_missing_values_by_type(builds_w_val_filled, 'VAL_Compr_max', col_type='VAL_Descr_Tipologia', k=10)\n",
    "del builds_w_val_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop useless cols\n",
    "cols_to_drop = ['Name', 'ZONE_Fascia', 'ZONE_Cod_tip_prev', 'ZONE_Descr_tip_prev', 'VAL_Cod_Tip', 'VAL_Stato']\n",
    "builds_w_val_filled_ok = builds_w_val_filled2.drop(cols_to_drop, axis=1)\n",
    "# drop nan\n",
    "builds_w_val_filled_ok.dropna(inplace=True)\n",
    "\n",
    "# save builds_w_val\n",
    "builds_w_val_filled_ok.to_file(\"ASSETS/pre-processed/builds_w_val_filled_by_type_new.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on condition\n",
    "# builds_w_val_filled_ok = gpd.read_file(\"ASSETS/pre-processed/builds_w_val_filled_by_type_new.gpkg\")\n",
    "condition = ((builds_w_val_filled_ok['edifc_uso_macro'] == '10') & builds_w_val_filled_ok['edifc_ty'].isin(['11', '12', '15', '16', '95']))\n",
    "builds_w_omi = builds_w_val_filled_ok.drop(builds_w_val_filled_ok[condition].index)\n",
    "#save gdf\n",
    "# builds_w_omi.to_file(\"ASSETS/pre-processed/builds_w_omi_all.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SJOIN BUILDS w CENSUS\n",
    "# spatial join one-to-one between buildings and census.\n",
    "cols_of_interest = ['id', 'geometry']\n",
    "cens_id = census_aoi[cols_of_interest].rename(columns={'id':'c_parcel_id'})\n",
    "builds_w_all = largest_intersection(builds_w_omi, cens_id, 'intersects')\n",
    "# drop rows with VAL_Descr_Tipologia == '-'.\n",
    "builds_w_all = builds_w_all.drop(builds_w_all[builds_w_all['VAL_Descr_Tipologia'] == '-'].index)\n",
    "\n",
    "# builds_w_all.to_file(\"ASSETS/pre-processed/builds_w_all.gpkg\", driver='GPKG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SPATIAL INTERPOLATION WITH TOBLER\n",
    "# interpolation = area_interpolate(source_df=omi_aoi, target_df=census_aoi, intensive_variables=['VAL_Compr_min_fill'])\n",
    "# interpolation.to_file(\"tests/census_w_omi_spatial_interpolation.gpkg\", driver='GPKG', layer='name')\n",
    "\n",
    "# buildings\n",
    "# interp_build = area_interpolate(omi_aoi, BUILD, intensive_variables=['VAL_Compr_min_fill', 'VAL_Compr_max_fill'])\n",
    "# interp_build.to_file(\"tests/builds_w_omi_spatial_interpolation.gpkg\", driver='GPKG', layer='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT VECTORS\n",
    "\n",
    "# font = {'family' : 'Sans Serif',\n",
    "#         'size'   : 18}\n",
    "# plt.rc('font', **font)\n",
    "plt.rc('font', size=12)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=12)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=11)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=11)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=11)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=12)    # legend fontsize\n",
    "plt.rc('figure', titlesize=14)  # fontsize of the figure title\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), dpi=500, facecolor='w', edgecolor='k')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "cx_crs = 'EPSG:3857'\n",
    "AOI.to_crs(cx_crs).boundary.plot(ax=ax, color='k')\n",
    "omi_codzona.to_crs(cx_crs).boundary.plot(ax=ax, color='k', lw=0.5, zorder=1)\n",
    "\n",
    "builds_w_val_filled2.to_crs(cx_crs).plot(ax=ax, column='VAL_Compr_max', cmap='rainbow', zorder=2,\n",
    "                          legend=True, cax=cax, legend_kwds={'label':'Euro/mq',\n",
    "                                                    'orientation':'vertical'})\n",
    "\n",
    "\n",
    "# interp_build.plot(ax=ax, column='VAL_Compr_max_fill', linewidth=0.1)\n",
    "\n",
    "# add basemap\n",
    "# cx.add_basemap(ax=ax, source=cx.providers.Stamen.TonerLite)\n",
    "# cx.add_basemap(ax, source=cx.providers.Esri.WorldTerrain) #WorldTerrain, WorldShadedRelief\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "\n",
    "# set labels, title and legend\n",
    "# plt.title('Building Value', fontsize=32)\n",
    "# ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "# add scalebar\n",
    "# ax.add_artist(ScaleBar(2, location='lower right', box_color='w', font_properties={'size':'large'}))\n",
    "\n",
    "# SAVE\n",
    "PLOT_NAME= 'Building Value by location and type'\n",
    "# plt.savefig(os.path.join(path, '{}.tiff').format(PLOT_NAME), format='tiff', bbox_inches='tight', pad_inches=0.2)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
